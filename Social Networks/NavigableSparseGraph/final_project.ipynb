{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigable graph: sparsity and pseudo-greedy routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import networkx as nx\n",
    "from tqdm import tqdm as tqdm \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import timeit\n",
    "from itertools import combinations\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from utils import greedyRouting, greedyRoutingRelax, secondDegreedy_full, Environment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The point is to investigate if, under milder routing algorithms, we can achieve navigable graphs sparser than the SOA. Two questions arise in this case:\n",
    "\n",
    "+ How do we build such graphs? \n",
    "+ How do we navigate them? \n",
    "\n",
    "To answer the first question, we are going to implement the pseudorandomized procedure from [Navigable Graphs for High-Dimensional Nearest Neighbor Search: Constructions and Limits](https://arxiv.org/html/2405.18680v1) that the authors used to prove the upper bound in the degree of a navigable graph. In particular, such a graph is build in two steps, resulting in the union of a $m$-NN graph and a ER one: \n",
    "\n",
    "+ Each node is connected with its $m = \\sqrt{n \\log n}$ closest nodes;\n",
    "+ Each node is randomely connected with $m = \\sqrt{n \\log n}$ nodes. \n",
    "\n",
    "The idea is to relax this construction trying the procedure with smaller values of $m$: then some routing algorithms are going to be tested on this graphs, relaxing the greedy approach. In particular we are going to consider:\n",
    "\n",
    "+ Higher order information in greedy routing;\n",
    "+ Random delivery when stuck. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the lower bound has been proved for points coming from the vertices of $d$-dimensional cubes, we are going to use such a setting equipped with Euclidean metric as our setting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "C = 10\n",
    "Env = Environment(N, 1, C, 'Uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 1., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 1., 1., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Env.randomizedConstruction()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
